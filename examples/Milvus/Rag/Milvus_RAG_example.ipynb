{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSNG3jtbw1go",
        "outputId": "c21cf449-31b7-43ba-e531-27ee84a090f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.6.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (75.2.0)\n",
            "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (1.75.0)\n",
            "Requirement already satisfied: protobuf>=5.27.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (5.29.5)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (1.1.1)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Downloading pymilvus-2.6.2-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson, requests, pymilvus, openai\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.108.0\n",
            "    Uninstalling openai-1.108.0:\n",
            "      Successfully uninstalled openai-1.108.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-1.109.1 pymilvus-2.6.2 requests-2.32.5 ujson-5.11.0\n",
            "Collecting git+https://github.com/JerzyKultura/Agora.git\n",
            "  Cloning https://github.com/JerzyKultura/Agora.git to /tmp/pip-req-build-qmepm_tx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JerzyKultura/Agora.git /tmp/pip-req-build-qmepm_tx\n",
            "  Resolved https://github.com/JerzyKultura/Agora.git to commit 1084050823fe6e5137f617621c1d403c91af34c5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: agora\n",
            "  Building wheel for agora (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for agora: filename=agora-0.1.0-py3-none-any.whl size=10450 sha256=c7540abe736f0c022b5e6dc6a497538a3dd8ff41efbeb342af599d8279d4f5f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3e24dozt/wheels/54/03/09/657d5c3da4e08b83a5da9904f69aa6f4e7fbc9f7660b3580ab\n",
            "Successfully built agora\n",
            "Installing collected packages: agora\n",
            "Successfully installed agora-0.1.0\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Collecting opentelemetry-instrumentation-openai\n",
            "  Downloading opentelemetry_instrumentation_openai-0.47.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api) (4.15.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk) (0.58b0)\n",
            "Collecting opentelemetry-instrumentation>=0.50b0 (from opentelemetry-instrumentation-openai)\n",
            "  Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.13 (from opentelemetry-instrumentation-openai)\n",
            "  Downloading opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api) (3.23.0)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation>=0.50b0->opentelemetry-instrumentation-openai) (25.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation>=0.50b0->opentelemetry-instrumentation-openai) (1.17.3)\n",
            "Downloading opentelemetry_instrumentation_openai-0.47.3-py3-none-any.whl (35 kB)\n",
            "Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl (33 kB)\n",
            "Downloading opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl (6.1 kB)\n",
            "Installing collected packages: opentelemetry-semantic-conventions-ai, opentelemetry-instrumentation, opentelemetry-instrumentation-openai\n",
            "Successfully installed opentelemetry-instrumentation-0.58b0 opentelemetry-instrumentation-openai-0.47.3 opentelemetry-semantic-conventions-ai-0.4.13\n",
            "Requirement already satisfied: pymilvus[milvus_lite] in /usr/local/lib/python3.12/dist-packages (2.6.2)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus_lite]) (75.2.0)\n",
            "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus_lite]) (1.75.0)\n",
            "Requirement already satisfied: protobuf>=5.27.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus_lite]) (5.29.5)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus_lite]) (1.1.1)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus_lite]) (5.11.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus_lite]) (2.2.2)\n",
            "Collecting milvus-lite>=2.4.0 (from pymilvus[milvus_lite])\n",
            "  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus[milvus_lite]) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from milvus-lite>=2.4.0->pymilvus[milvus_lite]) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus_lite]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[milvus_lite]) (1.17.0)\n",
            "Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: milvus-lite\n",
            "Successfully installed milvus-lite-2.5.1\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# RAG WITH AGORA + TELEMETRY\n",
        "# ============================================================================\n",
        "\n",
        "# Install dependencies\n",
        "!pip install --upgrade pymilvus openai requests tqdm\n",
        "!pip install --force-reinstall git+https://github.com/JerzyKultura/Agora.git\n",
        "!pip install opentelemetry-api opentelemetry-sdk opentelemetry-instrumentation-openai\n",
        "!pip install pymilvus[milvus_lite]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "from pymilvus import MilvusClient\n",
        "\n",
        "# Agora imports\n",
        "from agora.telemetry import AuditLogger, AuditedNode, AuditedFlow\n",
        "\n",
        "# OpenTelemetry setup\n",
        "from opentelemetry import trace\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor\n",
        "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
        "\n",
        "# Setup tracing\n",
        "trace.set_tracer_provider(TracerProvider())\n",
        "trace.get_tracer_provider().add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\n",
        "OpenAIInstrumentor().instrument()\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Download and extract data (only run once)\n",
        "!wget -q https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip\n",
        "!unzip -q milvus_docs_2.4.x_en.zip -d milvus_docs\n"
      ],
      "metadata": {
        "id": "8Gsp5q4u2miT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# AGORA RAG WORKFLOW NODES\n",
        "# ============================================================================\n",
        "\n",
        "class DocumentLoader(AuditedNode):\n",
        "    \"\"\"Load and split documents from markdown files\"\"\"\n",
        "\n",
        "    def prep(self, shared):\n",
        "        return \"milvus_docs/en/faq/*.md\"\n",
        "\n",
        "    def exec(self, file_pattern):\n",
        "        text_lines = []\n",
        "        files_processed = 0\n",
        "\n",
        "        for file_path in glob(file_pattern, recursive=True):\n",
        "            with open(file_path, \"r\") as file:\n",
        "                file_text = file.read()\n",
        "            text_lines += file_text.split(\"# \")\n",
        "            files_processed += 1\n",
        "\n",
        "        return {\"text_lines\": text_lines, \"files_processed\": files_processed}\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        shared[\"documents\"] = exec_res[\"text_lines\"]\n",
        "        print(f\"Loaded {len(exec_res['text_lines'])} text chunks from {exec_res['files_processed']} files\")\n",
        "        return \"embed\"\n",
        "\n",
        "class EmbeddingGenerator(AuditedNode):\n",
        "    \"\"\"Generate embeddings for text chunks using OpenAI\"\"\"\n",
        "\n",
        "    def prep(self, shared):\n",
        "        self.openai_client = OpenAI()\n",
        "        return shared[\"documents\"]\n",
        "\n",
        "    def exec(self, documents):\n",
        "        embeddings_data = []\n",
        "\n",
        "        for i, text in enumerate(tqdm(documents, desc=\"Creating embeddings\")):\n",
        "            if text.strip():  # Skip empty texts\n",
        "                embedding = self.openai_client.embeddings.create(\n",
        "                    input=text,\n",
        "                    model=\"text-embedding-3-small\"\n",
        "                ).data[0].embedding\n",
        "\n",
        "                embeddings_data.append({\n",
        "                    \"id\": i,\n",
        "                    \"vector\": embedding,\n",
        "                    \"text\": text\n",
        "                })\n",
        "\n",
        "        return embeddings_data\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        shared[\"embeddings_data\"] = exec_res\n",
        "        shared[\"embedding_dim\"] = len(exec_res[0][\"vector\"]) if exec_res else 0\n",
        "        print(f\"Generated {len(exec_res)} embeddings, dimension: {shared['embedding_dim']}\")\n",
        "        return \"store\"\n",
        "\n",
        "class MilvusStorer(AuditedNode):\n",
        "    \"\"\"Store embeddings in Milvus vector database\"\"\"\n",
        "\n",
        "    def prep(self, shared):\n",
        "        self.milvus_client = MilvusClient(uri=\"./milvus_demo.db\")\n",
        "        self.collection_name = \"rag_collection\"\n",
        "\n",
        "        # Setup collection\n",
        "        if self.milvus_client.has_collection(self.collection_name):\n",
        "            self.milvus_client.drop_collection(self.collection_name)\n",
        "\n",
        "        self.milvus_client.create_collection(\n",
        "            collection_name=self.collection_name,\n",
        "            dimension=shared[\"embedding_dim\"],\n",
        "            metric_type=\"IP\"\n",
        "        )\n",
        "\n",
        "        return shared[\"embeddings_data\"]\n",
        "\n",
        "    def exec(self, embeddings_data):\n",
        "        self.milvus_client.insert(\n",
        "            collection_name=self.collection_name,\n",
        "            data=embeddings_data\n",
        "        )\n",
        "        return len(embeddings_data)\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        shared[\"milvus_client\"] = self.milvus_client\n",
        "        shared[\"collection_name\"] = self.collection_name\n",
        "        print(f\"Stored {exec_res} vectors in Milvus collection\")\n",
        "        return \"ready\"\n",
        "\n",
        "# ============================================================================\n",
        "# RAG QUERY NODES\n",
        "# ============================================================================\n",
        "\n",
        "class QueryEmbedder(AuditedNode):\n",
        "    \"\"\"Convert query to embedding vector\"\"\"\n",
        "\n",
        "    def prep(self, shared):\n",
        "        self.openai_client = OpenAI()\n",
        "        return shared.get(\"question\", \"How is data stored in milvus?\")\n",
        "\n",
        "    def exec(self, question):\n",
        "        embedding = self.openai_client.embeddings.create(\n",
        "            input=question,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        ).data[0].embedding\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        shared[\"query_embedding\"] = exec_res\n",
        "        shared[\"question\"] = prep_res\n",
        "        print(f\"Generated embedding for query: {prep_res}\")\n",
        "        return \"search\"\n",
        "\n",
        "class VectorSearcher(AuditedNode):\n",
        "    \"\"\"Search Milvus for similar documents\"\"\"\n",
        "\n",
        "    def prep(self, shared):\n",
        "        return {\n",
        "            \"milvus_client\": shared[\"milvus_client\"],\n",
        "            \"collection_name\": shared[\"collection_name\"],\n",
        "            \"query_embedding\": shared[\"query_embedding\"]\n",
        "        }\n",
        "\n",
        "    def exec(self, search_params):\n",
        "        search_res = search_params[\"milvus_client\"].search(\n",
        "            collection_name=search_params[\"collection_name\"],\n",
        "            data=[search_params[\"query_embedding\"]],\n",
        "            limit=3,\n",
        "            search_params={\"metric_type\": \"IP\", \"params\": {}},\n",
        "            output_fields=[\"text\"]\n",
        "        )\n",
        "\n",
        "        retrieved_docs = [\n",
        "            (res[\"entity\"][\"text\"], res[\"distance\"])\n",
        "            for res in search_res[0]\n",
        "        ]\n",
        "\n",
        "        return retrieved_docs\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        shared[\"retrieved_docs\"] = exec_res\n",
        "        print(f\"Retrieved {len(exec_res)} relevant documents\")\n",
        "        print(f\"Top match distance: {exec_res[0][1]:.3f}\" if exec_res else \"No results\")\n",
        "        return \"generate\"\n",
        "\n",
        "class ResponseGenerator(AuditedNode):\n",
        "    \"\"\"Generate final RAG response using LLM\"\"\"\n",
        "\n",
        "    def prep(self, shared):\n",
        "        self.openai_client = OpenAI()\n",
        "\n",
        "        # Build context from retrieved documents\n",
        "        context = \"\\n\".join([doc[0] for doc in shared[\"retrieved_docs\"]])\n",
        "\n",
        "        return {\n",
        "            \"question\": shared[\"question\"],\n",
        "            \"context\": context\n",
        "        }\n",
        "\n",
        "    def exec(self, rag_input):\n",
        "        SYSTEM_PROMPT = \"\"\"\n",
        "        Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n",
        "        \"\"\"\n",
        "\n",
        "        USER_PROMPT = f\"\"\"\n",
        "        Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
        "        <context>\n",
        "        {rag_input[\"context\"]}\n",
        "        </context>\n",
        "        <question>\n",
        "        {rag_input[\"question\"]}\n",
        "        </question>\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.openai_client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": USER_PROMPT},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        shared[\"final_answer\"] = exec_res\n",
        "        print(\"Generated RAG response:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(exec_res)\n",
        "        print(\"-\" * 50)\n",
        "        return \"complete\"\n",
        "\n",
        "# ============================================================================\n",
        "# BUILD AND RUN RAG WORKFLOWS\n",
        "# ============================================================================\n",
        "\n",
        "def build_knowledge_base():\n",
        "    \"\"\"Build the knowledge base using Agora workflow\"\"\"\n",
        "\n",
        "    # Create audit logger\n",
        "    logger = AuditLogger(\"rag-indexing\")\n",
        "\n",
        "    # Create nodes\n",
        "    loader = DocumentLoader(\"DocumentLoader\", logger)\n",
        "    embedder = EmbeddingGenerator(\"EmbeddingGenerator\", logger)\n",
        "    storer = MilvusStorer(\"MilvusStorer\", logger)\n",
        "\n",
        "    # Create workflow\n",
        "    flow = AuditedFlow(\"RAGIndexing\", logger)\n",
        "    flow.start(loader)\n",
        "\n",
        "    # Build pipeline\n",
        "    loader - \"embed\" >> embedder\n",
        "    embedder - \"store\" >> storer\n",
        "\n",
        "    # Run indexing\n",
        "    shared = {}\n",
        "    flow.run(shared)\n",
        "\n",
        "    # Show audit results\n",
        "    print(f\"\\nIndexing Audit Summary: {logger.get_summary()}\")\n",
        "    logger.save_json(\"rag_indexing_audit.json\")\n",
        "\n",
        "    return shared\n",
        "\n",
        "def query_knowledge_base(shared, question=\"How is data stored in milvus?\"):\n",
        "    \"\"\"Query the knowledge base using Agora workflow\"\"\"\n",
        "\n",
        "    # Create audit logger\n",
        "    logger = AuditLogger(\"rag-query\")\n",
        "\n",
        "    # Create nodes\n",
        "    query_embedder = QueryEmbedder(\"QueryEmbedder\", logger)\n",
        "    searcher = VectorSearcher(\"VectorSearcher\", logger)\n",
        "    generator = ResponseGenerator(\"ResponseGenerator\", logger)\n",
        "\n",
        "    # Create workflow\n",
        "    flow = AuditedFlow(\"RAGQuery\", logger)\n",
        "    flow.start(query_embedder)\n",
        "\n",
        "    # Build pipeline\n",
        "    query_embedder - \"search\" >> searcher\n",
        "    searcher - \"generate\" >> generator\n",
        "\n",
        "    # Add question and existing state\n",
        "    shared[\"question\"] = question\n",
        "\n",
        "    # Run query\n",
        "    flow.run(shared)\n",
        "\n",
        "    # Show audit results\n",
        "    print(f\"\\nQuery Audit Summary: {logger.get_summary()}\")\n",
        "    logger.save_json(\"rag_query_audit.json\")\n",
        "\n",
        "    return shared\n",
        "\n",
        "# ============================================================================\n",
        "# RUN THE COMPLETE RAG SYSTEM\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# INTERACTIVE RAG CHAT\n",
        "# ============================================================================\n",
        "\n",
        "def interactive_rag_chat(shared_state):\n",
        "    \"\"\"Interactive chat with the RAG system\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INTERACTIVE RAG CHAT\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Ask questions about Milvus! Type 'exit' to quit.\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nYour question: \").strip()\n",
        "\n",
        "        if question.lower() in ['exit', 'quit', 'stop']:\n",
        "            print(\"Thanks for using RAG with Agora!\")\n",
        "            break\n",
        "\n",
        "        if not question:\n",
        "            print(\"Please enter a question.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing: {question}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Query the knowledge base\n",
        "        query_knowledge_base(shared_state, question)\n",
        "\n",
        "def run_full_rag_demo():\n",
        "    \"\"\"Run the complete RAG demo with Agora + Telemetry\"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"RAG WITH AGORA + TELEMETRY DEMO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Build knowledge base\n",
        "    print(\"\\n1. Building Knowledge Base...\")\n",
        "    shared_state = build_knowledge_base()\n",
        "\n",
        "    # Step 2: Demo queries\n",
        "    print(\"\\n2. Running Demo Queries...\")\n",
        "    query_knowledge_base(shared_state, \"How is data stored in milvus?\")\n",
        "\n",
        "    print(\"\\n3. Try another query...\")\n",
        "    query_knowledge_base(shared_state, \"What are the different types of indexes in Milvus?\")\n",
        "\n",
        "    # Step 3: Interactive mode\n",
        "    print(\"\\n4. Starting Interactive Mode...\")\n",
        "    interactive_rag_chat(shared_state)\n",
        "\n",
        "    print(\"\\nRAG Demo Complete!\")\n",
        "    print(\"Check the audit JSON files for detailed execution logs.\")\n",
        "\n",
        "# Run the demo\n",
        "print(\"Ready to run RAG with Agora!\")\n",
        "print(\"Execute: run_full_rag_demo()\")\n",
        "\n",
        "# Or run just the interactive chat after building knowledge base:\n",
        "# print(\"To run interactive chat only:\")\n",
        "# print(\"shared_state = build_knowledge_base()\")\n",
        "# print(\"interactive_rag_chat(shared_state)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxAzARsk2iHp",
        "outputId": "27ddd1fb-f2fb-4159-bf10-409d38ff247f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to run RAG with Agora!\n",
            "Execute: run_full_rag_demo()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_full_rag_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAAGxnSuxBcC",
        "outputId": "3fb6f6e4-d3f3-4d8a-f95b-2a7b0432725a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "RAG WITH AGORA + TELEMETRY DEMO\n",
            "============================================================\n",
            "\n",
            "1. Building Knowledge Base...\n",
            "Loaded 72 text chunks from 4 files\n",
            "{\n",
            "    \"name\": \"node.DocumentLoader\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x96fbf43c614a1660\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x1dd96534c4d793e7\",\n",
            "    \"start_time\": \"2025-09-26T11:51:05.649657Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:05.650612Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"DocumentLoader\",\n",
            "        \"node_type\": \"DocumentLoader\",\n",
            "        \"latency_ms\": 0.9207725524902344,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 2\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   0%|          | 0/72 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x566bf04e5f6c15b8\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:05.900595Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:06.568198Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"---\\nid: troubleshooting.md\\nsummary: Learn about common issues you may encounter with Milvus and how to overcome them.\\ntitle: Troubleshooting\\n---\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 32,\n",
            "        \"gen_ai.usage.prompt_tokens\": 32,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   1%|▏         | 1/72 [00:00<00:47,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x59582efe63160f9f\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:06.569671Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:07.089485Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Troubleshooting\\nThis page lists common issues that may occur when running Milvus, as well as possible troubleshooting tips. Issues on this page fall into the following categories:\\n\\n- [Boot issues](#boot_issues)\\n- [Runtime issues](#runtime_issues)\\n- [API issues](#api_issues)\\n- [etcd crash issues](#etcd_crash_issues)\\n\\n\\n  #\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 78,\n",
            "        \"gen_ai.usage.prompt_tokens\": 78,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   3%|▎         | 2/72 [00:01<00:40,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x9716276ce4dc09c1\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:07.090921Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:07.604184Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Boot issues\\n\\n  Boot errors are usually fatal. Run the following command to view error details:\\n\\n  ```\\n  $ docker logs <your milvus container id>\\n  ```\\n\\n\\n  #\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 38,\n",
            "        \"gen_ai.usage.prompt_tokens\": 38,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   4%|▍         | 3/72 [00:01<00:38,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x7445584fd1ee2b56\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:07.605665Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:08.172346Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Runtime issues\\n\\n  Errors that occur during runtime may cause service breakdown. To troubleshoot this issue, check compatibility between the server and your client before moving forward.\\n\\n\\n  #\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 34,\n",
            "        \"gen_ai.usage.prompt_tokens\": 34,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   6%|▌         | 4/72 [00:02<00:37,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x9201fc12eae077c0\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:08.173795Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:08.535687Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"API issues\\n\\n  These issues occur during API method calls between the Milvus server and your client. They will be returned to the client synchronously or asynchronously.\\n  \\n\\n  #\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 36,\n",
            "        \"gen_ai.usage.prompt_tokens\": 36,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   7%|▋         | 5/72 [00:02<00:32,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x71ce7e534a7c8ab0\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:08.537142Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:08.961974Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"etcd crash issues\\n  \\n  ##\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 7,\n",
            "        \"gen_ai.usage.prompt_tokens\": 7,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:   8%|▊         | 6/72 [00:03<00:30,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x92812c6698c8fcb9\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:08.963428Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:09.323855Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"1. etcd pod pending\\n\\n  The etcd cluster uses pvc by default. StorageClass needs to be preconfigured for the Kubernetes cluster.\\n\\n  ##\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 32,\n",
            "        \"gen_ai.usage.prompt_tokens\": 32,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  10%|▉         | 7/72 [00:03<00:28,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xe805e75992a3860f\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:09.325410Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:09.654747Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"2. etcd pod crash\\n\\n  When an etcd pod crashes with `Error: bad member ID arg (strconv.ParseUint: parsing \\\"\\\": invalid syntax), expecting ID in Hex`, you can log into this pod and delete the `/bitnami/etcd/data/member_id` file.\\n\\n  ##\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 62,\n",
            "        \"gen_ai.usage.prompt_tokens\": 62,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  11%|█         | 8/72 [00:03<00:25,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xe1afa2905cc79573\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:09.656221Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:10.240216Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"3. Multiple pods keep crashing while `etcd-0` is still running\\n\\n  You can run the following code if multiple pods keeps crashing while `etcd-0` is still running.\\n  \\n  ```\\n  kubectl scale sts <etcd-sts> --replicas=1\\n  \",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 61,\n",
            "        \"gen_ai.usage.prompt_tokens\": 61,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  12%|█▎        | 9/72 [00:04<00:28,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x2f0c974356e71c75\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:10.241627Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:10.745368Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"delete the pvc for etcd-1 and etcd-2\\n  kubectl scale sts <etcd-sts> --replicas=3\\n  ```\\n  \\n  ##\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 37,\n",
            "        \"gen_ai.usage.prompt_tokens\": 37,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  14%|█▍        | 10/72 [00:04<00:29,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x51df61a72ead6a6a\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:10.747237Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:11.192985Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"4. All pods crash\\n  \\n  When all pods crash, try copying the `/bitnami/etcd/data/member/snap/db` file. Use `https://github.com/etcd-io/bbolt` to modify database data.\\n\\n  All Milvus metadata are kept in the `key` bucket. Back up the data in this bucket and run the following commands. Note that the prefix data in the `by-dev/meta/session` file does not require a backup.\\n  \\n  ```\\n  kubectl kubectl scale sts <etcd-sts> --replicas=0\\n  \",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 119,\n",
            "        \"gen_ai.usage.prompt_tokens\": 119,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  15%|█▌        | 11/72 [00:05<00:28,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x343299b59a273707\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:11.194615Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:11.699517Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"delete the pvc for etcd-0, etcd-1, etcd-2\\n  kubectl kubectl scale sts <etcd-sts> --replicas=1\\n  \",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 40,\n",
            "        \"gen_ai.usage.prompt_tokens\": 40,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  17%|█▋        | 12/72 [00:05<00:28,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x556d7057b914f225\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:11.701005Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:12.221963Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"restore the backup data\\n  ```\\n\\n\\n\\n<br/>\\n\\n  If you need help solving a problem, feel free to:\\n\\n  - Join our [Slack channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) and reach out for support from the Milvus team.\\n  - [File an Issue](https://github.com/milvus-io/milvus/issues/new/choose) on GitHub that includes details about your problem.\\n\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 177,\n",
            "        \"gen_ai.usage.prompt_tokens\": 177,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  18%|█▊        | 13/72 [00:06<00:28,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x1648d165c56e34a3\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:12.223421Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:13.110516Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"---\\nid: operational_faq.md\\nsummary: Find answers to commonly asked questions about operations in Milvus.\\ntitle: Operational FAQ\\n---\\n\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 29,\n",
            "        \"gen_ai.usage.prompt_tokens\": 29,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  19%|█▉        | 14/72 [00:07<00:35,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xdf23e003df450c20\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:13.112008Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:13.441635Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Operational FAQ\\n\\n<!-- TOC -->\\n\\n\\n<!-- /TOC -->\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 14,\n",
            "        \"gen_ai.usage.prompt_tokens\": 14,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  21%|██        | 15/72 [00:07<00:30,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x941d6ae9cb47a621\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:13.443113Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:13.843099Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What if I failed to pull the Milvus Docker image from Docker Hub?\\n\\nIf you failed to pull the Milvus Docker image from Docker Hub, try adding other registry mirrors. \\n\\nUsers from Mainland China can add the URL \\\"https://registry.docker-cn.com\\\" to the registry-mirrors array in **/etc.docker/daemon.json**.\\n\\n```\\n{\\n  \\\"registry-mirrors\\\": [\\\"https://registry.docker-cn.com\\\"]\\n}\\n```\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 94,\n",
            "        \"gen_ai.usage.prompt_tokens\": 94,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  22%|██▏       | 16/72 [00:07<00:27,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xc2ad0087d0c48a21\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:13.844608Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:14.240322Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Is Docker the only way to install and run Milvus?\\n\\nDocker is an efficient way to deploy Milvus, but not the only way. You can also deploy Milvus from source code. This requires Ubuntu (18.04 or higher) or CentOS (7 or higher). See [Building Milvus from Source Code](https://github.com/milvus-io/milvus#build-milvus-from-source-code) for more information.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 97,\n",
            "        \"gen_ai.usage.prompt_tokens\": 97,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  24%|██▎       | 17/72 [00:08<00:25,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x284cdd8f41ddfc7d\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:14.242334Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:14.698775Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What are the main factors affecting recall?\\n\\nRecall is affected mainly by index type and search parameters.\\n\\nFor FLAT index, Milvus takes an exhaustive scan within a collection, with a 100% return.\\n\\nFor IVF indexes, the nprobe parameter determines the scope of a search within the collection. Increasing nprobe increases the proportion of vectors searched and recall, but diminishes query performance.\\n\\nFor HNSW index, the ef parameter determines the breadth of the graph search. Increasing ef increases the number of points searched on the graph and recall, but diminishes query performance.\\n\\nFor more information, see [Vector Indexing](https://www.zilliz.com/blog/Accelerating-Similarity-Search-on-Really-Big-Data-with-Vector-Indexing).\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 159,\n",
            "        \"gen_ai.usage.prompt_tokens\": 159,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  25%|██▌       | 18/72 [00:08<00:24,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x4b29f8aa92248ffd\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:14.700272Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:15.214252Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why did my changes to the configuration files not take effect?\\n\\nMilvus does not support modification to configuration files during runtime. You must restart Milvus Docker for configuration file changes to take effect.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 41,\n",
            "        \"gen_ai.usage.prompt_tokens\": 41,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  26%|██▋       | 19/72 [00:09<00:25,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x3866f914d2525ffa\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:15.215810Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:15.765918Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How do I know if Milvus has started successfully?\\n\\nIf Milvus is started using Docker Compose, run `docker ps` to observe how many Docker containers are running and check if Milvus services started correctly.\\n\\nFor Milvus standalone, you should be able to observe at least three running Docker containers, one being the Milvus service and the other two being etcd management and storage service. For more information, see [Installing Milvus Standalone](install_standalone-docker.md).\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 105,\n",
            "        \"gen_ai.usage.prompt_tokens\": 105,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  28%|██▊       | 20/72 [00:09<00:25,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xdaab87dd0d3f7e44\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:15.767467Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:16.108608Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why is the time in the log files different from the system time?\\n\\nThe time difference is usually due to the fact that the host machine does not use Coordinated Universal Time (UTC).\\n\\nThe log files inside the Docker image use UTC by default. If your host machine does not use UTC, this issue may occur.\\n\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 64,\n",
            "        \"gen_ai.usage.prompt_tokens\": 64,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  29%|██▉       | 21/72 [00:10<00:23,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xd33e213f46f61235\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:16.110073Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:16.571829Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How do I know if my CPU supports Milvus?\\n\\n{{fragments/cpu_support.md}}\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 20,\n",
            "        \"gen_ai.usage.prompt_tokens\": 20,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  31%|███       | 22/72 [00:10<00:22,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x99e13be7c46691b1\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:16.573732Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:16.959524Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why does Milvus return `illegal instruction` during startup?\\n\\nMilvus requires your CPU to support a SIMD instruction set: SSE4.2, AVX, AVX2, or AVX512. CPU must support at least one of these to ensure that Milvus operates normally. An `illegal instruction` error returned during startup suggests that your CPU does not support any of the above four instruction sets.\\n\\nSee [CPU\\u2019s support for SIMD Instruction Set](prerequisite-docker.md).\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 101,\n",
            "        \"gen_ai.usage.prompt_tokens\": 101,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  32%|███▏      | 23/72 [00:11<00:21,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xe524b089cb2830a0\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:16.961448Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:17.360092Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can I install Milvus on Windows?\\n\\nYes. You can install Milvus on Windows either by compiling from source code or from a binary package. \\n\\nSee [Run Milvus on Windows](https://milvus.io/blog/2021-11-19-run-milvus-2.0-on-windows.md) to learn how to install Milvus on Windows.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 80,\n",
            "        \"gen_ai.usage.prompt_tokens\": 80,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  33%|███▎      | 24/72 [00:11<00:20,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x499e0f6575681572\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:17.361545Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:17.752195Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"I got an error when installing pymilvus on Windows. What shall I do?\\n\\nIt is not recommended to install PyMilvus on Windows. But if you have to install PyMilvus on Windows but got an error, try installing it in a [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html) environment. See [Install Milvus SDK](install-pymilvus.md) for more information about how to install PyMilvus in the Conda environment.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 110,\n",
            "        \"gen_ai.usage.prompt_tokens\": 110,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  35%|███▍      | 25/72 [00:11<00:19,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x1cea2a67463736c5\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:17.753765Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:18.047540Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can I deploy Milvus when disconnected from the Internet?\\n\\nYes. You can install Milvus in an offline environment. See [Install Milvus Offline](install_offline-helm.md) for more information.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 45,\n",
            "        \"gen_ai.usage.prompt_tokens\": 45,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  36%|███▌      | 26/72 [00:12<00:17,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x82e2fc45e5e53fde\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:18.049024Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:18.432831Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Where can I find the logs generated by Milvus?\\n\\nThe Milvus log is printed to stout (standard output) and stderr (standard error) by default, however we highly recommend redirecting your log to a persistent volume in production. To do so, update `log.file.rootPath` in **milvus.yaml**. And if you deploy Milvus with `milvus-helm` chart, you also need to enable log persistence first via `--set log.persistence.enabled=true`. \\n\\nIf you didn't change the config, using kubectl logs <pod-name> or docker logs CONTAINER can also help you to find the log.\\n\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 134,\n",
            "        \"gen_ai.usage.prompt_tokens\": 134,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  38%|███▊      | 27/72 [00:12<00:17,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x08868dc87e811b15\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:18.434253Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:18.780654Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can I create index for a segment before inserting data into it?\\n\\nYes, you can. But we recommend inserting data in batches, each of which should not exceed 256 MB, before indexing each segment.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 42,\n",
            "        \"gen_ai.usage.prompt_tokens\": 42,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  39%|███▉      | 28/72 [00:12<00:16,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xeb10323fa07205ba\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:18.782091Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:19.405309Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can I share an etcd instance among multiple Milvus instances?\\n\\nYes, you can share an etcd instance among multiple Milvus instances. To do so, you need to change `etcd.rootPath` to a separate value for each Milvus instance in the configuration files of each before starting them.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 65,\n",
            "        \"gen_ai.usage.prompt_tokens\": 65,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  40%|████      | 29/72 [00:13<00:19,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xaf6a46dd73c1e41e\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:19.406898Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:19.979319Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can I share a Pulsar instance among multiple Milvus instances?\\n\\nYes, you can share a Pulsar instance among multiple Milvus instances. To do so, you can\\n\\n- If multi-tenancy is enabled on your Pulsar instance, consider allocating a separate tenant or namespace for each Milvus instance. To do so, you need to change `pulsar.tenant` or `pulsar.namespace` in the configuration files of your Milvus instances to a unique value for each before starting them.\\n- If you do not plan on enabling multi-tenancy on your Pulsar instance, consider changing `msgChannel.chanNamePrefix.cluster` in the configuration files of your Milvus instances to a unique value for each before starting them.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 161,\n",
            "        \"gen_ai.usage.prompt_tokens\": 161,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  42%|████▏     | 30/72 [00:14<00:20,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xab361546d3c436e1\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:19.980819Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:20.307603Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can I share a MinIO instance among multiple Milvus instances?\\n\\nYes, you can share a MinIO instance among multiple Milvus instances. To do so, you need to change `minio.rootPath` to a unique value for each Milvus instance in the configuration files of each before starting them.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 65,\n",
            "        \"gen_ai.usage.prompt_tokens\": 65,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  43%|████▎     | 31/72 [00:14<00:17,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x0231320d3a6fba39\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:20.309043Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:20.738130Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Still have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. Feel free to ask questions, share ideas, and help others.\\n- Join our [Milvus Forum](https://discuss.milvus.io/) or [Slack Channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 181,\n",
            "        \"gen_ai.usage.prompt_tokens\": 181,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  44%|████▍     | 32/72 [00:14<00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x910f86f2661a7a2e\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:20.739544Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:21.267067Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"---\\nid: performance_faq.md\\nsummary: Find answers to frequently asked questions about search performance, performance enhancements, and other performance related issues.\\ntitle: Performance FAQ\\n---\\n\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 35,\n",
            "        \"gen_ai.usage.prompt_tokens\": 35,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  46%|████▌     | 33/72 [00:15<00:18,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xf842d9b8562b9750\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:21.268550Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:21.693447Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Performance FAQ\\n\\n<!-- TOC -->\\n\\n\\n<!-- /TOC -->\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 13,\n",
            "        \"gen_ai.usage.prompt_tokens\": 13,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  47%|████▋     | 34/72 [00:15<00:17,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xb73353cc4abab12b\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:21.695067Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:22.050015Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How to set `nlist` and `nprobe` for IVF indexes?\\n\\nSetting `nlist` is scenario-specific. As a rule of thumb, the recommended value of `nlist` is `4 \\u00d7 sqrt(n)`, where `n` is the total number of entities in a segment.\\n\\nThe size of each segment is determined by the `datacoord.segment.maxSize` parameter, which is set to 512 MB by default. The total number of entities in a segment n can be estimated by dividing `datacoord.segment.maxSize` by the size of each entity.\\n\\nSetting `nprobe` is specific to the dataset and scenario, and involves a trade-off between accuracy and query performance. We recommend finding the ideal value through repeated experimentation.\\n\\nThe following charts are results from a test running on the sift50m dataset and IVF_SQ8 index, which compares recall and query performance of different `nlist`/`nprobe` pairs.\\n\\n![Accuracy test](../../../assets/accuracy_nlist_nprobe.png \\\"Accuracy test.\\\")\\n![Performance test](../../../assets/performance_nlist_nprobe.png \\\"Performance test.\\\")\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 229,\n",
            "        \"gen_ai.usage.prompt_tokens\": 229,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  49%|████▊     | 35/72 [00:16<00:15,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x89fd156740fd3c8b\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:22.051597Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:22.404147Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why do queries sometimes take longer on smaller datasets?\\n\\nQuery operations are conducted on segments. indexes reduce the amount of time it takes to query a segment. If a segment has not been indexed, Milvus resorts to brute-force search on the raw data\\u2014drastically increasing query time.\\n\\nTherefore, it usually takes longer to query on a small dataset (collection) because it has not built index. This is because the sizes of its segments have not reached the index-building threshold set by `rootCoord.minSegmentSizeToEnableindex`. Call `create_index()` to force Milvus to index segments that have reached the threshold but not yet been automatically indexed, significantly improving query performance.\\n\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 137,\n",
            "        \"gen_ai.usage.prompt_tokens\": 137,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  50%|█████     | 36/72 [00:16<00:14,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xc52d2fb5f468225c\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:22.406008Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:22.788376Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What factors impact CPU usage?\\n\\nCPU usage increases when Milvus is building indexes or running queries. In general, index building is CPU intensive except when using Annoy, which runs on a single thread.\\n\\nWhen running queries, CPU usage is affected by `nq` and `nprobe`. When `nq` and `nprobe` are small, concurrency is low and CPU usage stays low.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 83,\n",
            "        \"gen_ai.usage.prompt_tokens\": 83,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  51%|█████▏    | 37/72 [00:16<00:13,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xb83d7717420f216d\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:22.789801Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:23.156831Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does simultaneously inserting data and searching impact query performance?\\n\\nInsert operations are not CPU intensive. However, because new segments may not have reached the threshold for index building, Milvus resorts to brute-force search\\u2014significantly impacting query performance.\\n\\nThe `rootcoord.minSegmentSizeToEnableIndex` parameter determines the index-building threshold for a segment, and is set to 1024 rows by default. See [System Configuration](system_configuration.md) for more information.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 93,\n",
            "        \"gen_ai.usage.prompt_tokens\": 93,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  53%|█████▎    | 38/72 [00:17<00:13,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xca8d3df7107dcaff\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:23.158290Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:23.541217Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Still have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. Feel free to ask questions, share ideas, and help others.\\n- Join our [Slack Channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 164,\n",
            "        \"gen_ai.usage.prompt_tokens\": 164,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  54%|█████▍    | 39/72 [00:17<00:12,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x932c850d42dc1e0a\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:23.542606Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:23.889357Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"---\\nid: product_faq.md\\nsummary: Find answers to frequently asked questions about the world's most advanced vector database.\\ntitle: Product FAQ\\n---\\n\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 31,\n",
            "        \"gen_ai.usage.prompt_tokens\": 31,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  56%|█████▌    | 40/72 [00:17<00:12,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xdc896f141c71c272\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:23.890730Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:24.210715Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Product FAQ\\n\\n<!-- TOC -->\\n\\n\\n\\n<!-- /TOC -->\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 14,\n",
            "        \"gen_ai.usage.prompt_tokens\": 14,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  57%|█████▋    | 41/72 [00:18<00:11,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x6ea9e2193e1018ab\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:24.212137Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:24.875816Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How much does Milvus cost?\\n\\nMilvus is a 100% free open-source project.\\n\\nPlease adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.\\n\\nZilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 121,\n",
            "        \"gen_ai.usage.prompt_tokens\": 121,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  58%|█████▊    | 42/72 [00:18<00:13,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x69c97ac362356c68\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:24.877263Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:25.270256Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does Milvus support non-x86 architectures?\\n\\nMilvus cannot be installed or run on non-x86 platforms.\\n\\nYour CPU must support one of the following instruction sets to run Milvus: SSE4.2, AVX, AVX2, AVX512. These are all x86-dedicated SIMD instruction sets.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 69,\n",
            "        \"gen_ai.usage.prompt_tokens\": 69,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  60%|█████▉    | 43/72 [00:19<00:12,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xda226a90d2e26155\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:25.271766Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:25.887313Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What is the maximum dataset size Milvus can handle?\\n\\n  \\nTheoretically, the maximum dataset size Milvus can handle is determined by the hardware it is run on, specifically system memory and storage:\\n\\n- Milvus loads all specified collections and partitions into memory before running queries. Therefore, memory size determines the maximum amount of data Milvus can query.\\n- When new entities and and collection-related schema (currently only MinIO is supported for data persistence) are added to Milvus, system storage determines the maximum allowable size of inserted data.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 113,\n",
            "        \"gen_ai.usage.prompt_tokens\": 113,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  61%|██████    | 44/72 [00:19<00:13,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x787d5fa2c9af21e2\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:25.888794Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:26.233838Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \" Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 197,\n",
            "        \"gen_ai.usage.prompt_tokens\": 197,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  62%|██████▎   | 45/72 [00:20<00:12,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xb5ff7d182ad60d8e\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:26.235247Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:26.935750Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why is there no vector data in etcd?\\n\\netcd stores Milvus module metadata; MinIO stores entities.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 25,\n",
            "        \"gen_ai.usage.prompt_tokens\": 25,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  64%|██████▍   | 46/72 [00:21<00:13,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x74ce726edb4b3699\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:26.937277Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:27.310036Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does Milvus support inserting and searching data simultaneously?\\n\\nYes. Insert operations and query operations are handled by two separate modules that are mutually independent. From the client\\u2019s perspective, an insert operation is complete when the inserted data enters the message queue. However, inserted data are unsearchable until they are loaded to the query node. If the segment size does not reach the index-building threshold (512 MB by default), Milvus resorts to brute-force search and query performance may be diminished.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 99,\n",
            "        \"gen_ai.usage.prompt_tokens\": 99,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  65%|██████▌   | 47/72 [00:21<00:11,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x176ee70bed82dab0\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:27.311491Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:27.665687Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can vectors with duplicate primary keys be inserted into Milvus?\\n\\nYes. Milvus does not check if vector primary keys are duplicates.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 29,\n",
            "        \"gen_ai.usage.prompt_tokens\": 29,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  67%|██████▋   | 48/72 [00:21<00:10,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x24f42a489cd742cf\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:27.667104Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:28.005072Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"When vectors with duplicate primary keys are inserted, does Milvus treat it as an update operation?\\n\\nNo. Milvus does not currently support update operations and does not check if entity primary keys are duplicates. You are responsible for ensuring entity primary keys are unique, and if they aren't Milvus may contain multiple entities with duplicate primary keys.\\n\\nIf this occurs, which data copy will return when queried remains an unknown behavior. This limitation will be fixed in future releases.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 96,\n",
            "        \"gen_ai.usage.prompt_tokens\": 96,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  68%|██████▊   | 49/72 [00:22<00:09,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xd83c8649f53fe832\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:28.006918Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:28.415272Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What is the maximum length of self-defined entity primary keys?\\n\\nEntity primary keys must be non-negative 64-bit integers.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 25,\n",
            "        \"gen_ai.usage.prompt_tokens\": 25,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  69%|██████▉   | 50/72 [00:22<00:09,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xa0746d28235b12e1\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:28.416820Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:28.765415Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What is the maximum amount of data that can be added per insert operation?\\n\\nAn insert operation must not exceed 1,024 MB in size. This is a limit imposed by gRPC.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 39,\n",
            "        \"gen_ai.usage.prompt_tokens\": 39,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  71%|███████   | 51/72 [00:22<00:08,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xd4a8e211d3e9c37d\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:28.766763Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:29.330381Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does collection size impact query performance when searching in a specific partition?\\n\\nNo. If partitions for a search are specified, Milvus searches the specified partitions only.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 33,\n",
            "        \"gen_ai.usage.prompt_tokens\": 33,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  72%|███████▏  | 52/72 [00:23<00:08,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xa02870a368794921\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:29.331880Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:29.695263Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does Milvus load the entire collection when partitions are specified for a search?\\n\\nNo. Milvus has varied behavior. Data must be loaded to memory before searching.\\n\\n- If you know which partitions your data are located in, call `load_partition()` to load the intended partition(s) *then* specify partition(s) in the `search()` method call.\\n- If you do not know the exact partitions, call `load_collection()` before calling `search()`.\\n- If you fail to load collections or partitions before searching, Milvus returns an error.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 114,\n",
            "        \"gen_ai.usage.prompt_tokens\": 114,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  74%|███████▎  | 53/72 [00:23<00:07,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x326226622ac746f0\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:29.697129Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:30.198828Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Can indexes be created after inserting vectors?\\n\\nYes. If an index has been built for a collection by `create_index()` before, Milvus will automatically build an index for subsequently inserted vectors. However, Milvus does not build an index until the newly inserted vectors fill an entire segment and the newly created index file is separate from the previous one.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 72,\n",
            "        \"gen_ai.usage.prompt_tokens\": 72,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  75%|███████▌  | 54/72 [00:24<00:08,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x9968bb2e2c5489b6\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:30.200292Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:30.651264Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How are the FLAT and IVF_FLAT indexes different?\\n\\nThe IVF_FLAT index divides vector space into list clusters. At the default list value of 16,384, Milvus compares the distances between the target vector and the centroids of all 16,384 clusters to return probe nearest clusters. Milvus then compares the distances between the target vector and the vectors in the selected clusters to get the nearest vectors. Unlike IVF_FLAT, FLAT directly compares the distances between the target vector and every other vector.\\n\\nWhen the total number of vectors approximately equals nlist, there is little distance between IVF_FLAT and FLAT in terms of calculation requirements and search performance. However, as the number of vectors exceeds nlist by a factor of two or more, IVF_FLAT begins to demonstrate performance advantages.\\n\\nSee [Vector Index](index.md) for more information.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 181,\n",
            "        \"gen_ai.usage.prompt_tokens\": 181,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  76%|███████▋  | 55/72 [00:24<00:07,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x301cca6aee7a953f\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:30.652730Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:31.051847Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How does Milvus flush data?\\n\\nMilvus returns success when inserted data are loaded to the message queue. However, the data are not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 82,\n",
            "        \"gen_ai.usage.prompt_tokens\": 82,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  78%|███████▊  | 56/72 [00:25<00:06,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xd0c8f51593356a28\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:31.053222Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:31.417188Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What is normalization? Why is normalization needed?\\n\\nNormalization refers to the process of converting a vector so that its norm equals 1. If inner product is used to calculate vector similarity, vectors must be normalized. After normalization, inner product equals cosine similarity.\\n\\nSee [Wikipedia](https://en.wikipedia.org/wiki/Unit_vector) for more information.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 70,\n",
            "        \"gen_ai.usage.prompt_tokens\": 70,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  79%|███████▉  | 57/72 [00:25<00:06,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x4d6656674757746c\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:31.418612Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:31.853903Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why do Euclidean distance (L2) and inner product (IP) return different results?\\n\\nFor normalized vectors, Euclidean distance (L2) is mathematically equivalent to inner product (IP). If these similarity metrics return different results, check to see if your vectors are normalized\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 59,\n",
            "        \"gen_ai.usage.prompt_tokens\": 59,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  81%|████████  | 58/72 [00:25<00:05,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x47b54e254a88b9bf\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:31.855350Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:32.165475Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Is there a limit to the total number of collections and partitions in Milvus?\\n\\nYes. You can create up to 65,535 collections in a Milvus instance. When calculating the number of existing collections, Milvus counts all collections with shards and partitions in them.\\n\\nFor example, let's assume you have already created 100 collections, with 2 shards and 4 partitions in 60 of them and with 1 shard and 12 partitions in the rest 40 collections. The current number of collections can be calculated as:\\n\\n```\\n60 * 2 * 4 + 40 * 1 * 12 = 960\\n```\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 135,\n",
            "        \"gen_ai.usage.prompt_tokens\": 135,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  82%|████████▏ | 59/72 [00:26<00:05,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x3ad8de83a5e8ed2c\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:32.166973Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:32.503020Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why do I get fewer than k vectors when searching for `topk` vectors?\\n\\nAmong the indexes that Milvus supports, IVF_FLAT and IVF_SQ8 implement the k-means clustering method. A data space is divided into `nlist` clusters and the inserted vectors are distributed to these clusters. Milvus then selects the `nprobe` nearest clusters and compares the distances between the target vector and all vectors in the selected clusters to return the final results.\\n\\nIf `nlist` and `topk` are large and nprobe is small, the number of vectors in the nprobe clusters may be less than `k`. Therefore, when you search for the `topk` nearest vectors, the number of returned vectors is less than `k`.\\n\\nTo avoid this, try setting `nprobe` larger and `nlist` and `k` smaller.\\n\\nSee [Vector Index](index.md) for more information.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 192,\n",
            "        \"gen_ai.usage.prompt_tokens\": 192,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  83%|████████▎ | 60/72 [00:26<00:04,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xe92103028b4a4611\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:32.504503Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:32.901078Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What is the maximum vector dimension supported in Milvus?\\n\\nMilvus can manage vectors with up to 32,768 dimensions by default. You can increase the value of `Proxy.maxDimension` to allow for a larger dimension vector.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 49,\n",
            "        \"gen_ai.usage.prompt_tokens\": 49,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  85%|████████▍ | 61/72 [00:27<00:04,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x8df72e0f75c5c801\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:32.902609Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:33.629132Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does Milvus support Apple M1 CPU?\\n\\nCurrent Milvus release does not support Apple M1 CPU.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 24,\n",
            "        \"gen_ai.usage.prompt_tokens\": 24,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  86%|████████▌ | 62/72 [00:27<00:04,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x36b1cb382a34d757\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:33.630956Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:33.968688Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What data types does Milvus support on the primary key field?\\n\\nIn current release, Milvus supports both INT64 and string.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 29,\n",
            "        \"gen_ai.usage.prompt_tokens\": 29,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  88%|████████▊ | 63/72 [00:28<00:03,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xd52bcc617f71637d\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:33.970086Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:34.357109Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Is Milvus scalable?\\n\\nYes. You can deploy Milvus cluster with multiple nodes via Helm Chart on Kubernetes. Refer to [Scale Guide](scaleout.md) for more instruction.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 39,\n",
            "        \"gen_ai.usage.prompt_tokens\": 39,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  89%|████████▉ | 64/72 [00:28<00:03,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xf882efd451eaa857\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:34.358519Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:34.703633Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does the query perform in memory? What are incremental data and historical data?\\n\\nYes. When a query request comes, Milvus searches both incremental data and historical data by loading them into memory. Incremental data are in the growing segments, which are buffered in memory before they reach the threshold to be persisted in storage engine, while historical data are from the sealed segments that are stored in the object storage. Incremental data and historical data together constitute the whole dataset to search.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 96,\n",
            "        \"gen_ai.usage.prompt_tokens\": 96,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  90%|█████████ | 65/72 [00:28<00:02,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xd2717aa6ea5f32ab\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:34.704954Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:35.057919Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Is Milvus available for concurrent search?\\n\\nYes. For queries on the same collection, Milvus concurrently searches the incremental and historical data. However, queries on different collections are conducted in series. Whereas the historical data can be an extremely huge dataset, searches on the historical data are relatively more time-consuming and essentially performed in series.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 68,\n",
            "        \"gen_ai.usage.prompt_tokens\": 68,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  92%|█████████▏| 66/72 [00:29<00:02,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x70faead994daee42\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:35.059343Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:35.364014Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why does the data in MinIO remain after the corresponding collection is dropped?\\n\\nData in MinIO is designed to remain for a certain period of time for the convenience of data rollback.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 37,\n",
            "        \"gen_ai.usage.prompt_tokens\": 37,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  93%|█████████▎| 67/72 [00:29<00:01,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x51811de589ceee94\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:35.365443Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:35.863982Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Does Milvus support message engines other than Pulsar?\\n\\nYes. Kafka is supported in Milvus 2.1.0.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 30,\n",
            "        \"gen_ai.usage.prompt_tokens\": 30,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  94%|█████████▍| 68/72 [00:29<00:01,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xb60557ec80912323\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:35.865510Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:36.323559Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What's the difference between a search and a query?\\n\\nIn Milvus, a vector similarity search retrieves vectors based on similarity calculation and vector index acceleration. Unlike a vector similarity search, a vector query retrieves vectors via scalar filtering based on a boolean expression. The boolean expression filters on scalar fields or the primary key field, and it retrieves all results that match the filters. In a query, neither similarity metrics nor vector index is involved.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 88,\n",
            "        \"gen_ai.usage.prompt_tokens\": 88,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  96%|█████████▌| 69/72 [00:30<00:01,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xbf4f1a72f76c95f4\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:36.325006Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:36.625239Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Why does a float vector value have a precision of 7 decimal digits in Milvus?\\n\\nMilvus supports storing vectors as Float32 arrays. A Float32 value has a precision of 7 decimal digits. Even with a Float64 value, such as 1.3476964684980388, Milvus stores it as 1.347696. Therefore, when you retrieve such a vector from Milvus, the precision of the Float64 value is lost.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 98,\n",
            "        \"gen_ai.usage.prompt_tokens\": 98,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  97%|█████████▋| 70/72 [00:30<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x6684c1eb22e545e7\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:36.626710Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:37.149476Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n###\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 145,\n",
            "        \"gen_ai.usage.prompt_tokens\": 145,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating embeddings:  99%|█████████▊| 71/72 [00:31<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x714db5efb2b95ef6\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x696b966f8eddee81\",\n",
            "    \"start_time\": \"2025-09-26T11:51:37.150945Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:37.476106Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"Still have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. You're welcome to raise questions, share ideas, and help others.\\n- Join our [Slack community](https://slack.milvus.io/) to find support and engage with our open-source community.\\n\\n\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 75,\n",
            "        \"gen_ai.usage.prompt_tokens\": 75,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating embeddings: 100%|██████████| 72/72 [00:31<00:00,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 72 embeddings, dimension: 1536\n",
            "{\n",
            "    \"name\": \"node.EmbeddingGenerator\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x696b966f8eddee81\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x1dd96534c4d793e7\",\n",
            "    \"start_time\": \"2025-09-26T11:51:05.651489Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:37.477931Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"EmbeddingGenerator\",\n",
            "        \"node_type\": \"EmbeddingGenerator\",\n",
            "        \"latency_ms\": 31826.44534111023,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 72\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 72 vectors in Milvus collection\n",
            "{\n",
            "    \"name\": \"node.MilvusStorer\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0xe4a1d49ee5777cfc\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x1dd96534c4d793e7\",\n",
            "    \"start_time\": \"2025-09-26T11:51:37.478880Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:38.823523Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"MilvusStorer\",\n",
            "        \"node_type\": \"MilvusStorer\",\n",
            "        \"latency_ms\": 1344.6521759033203,\n",
            "        \"result_type\": \"str\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"flow.RAGIndexing\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x22c7036c972470382284791931d2406f\",\n",
            "        \"span_id\": \"0x1dd96534c4d793e7\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-09-26T11:51:05.649509Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:38.824431Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"flow_name\": \"RAGIndexing\",\n",
            "        \"flow_type\": \"AuditedFlow\",\n",
            "        \"total_latency_ms\": 33174.99661445618\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "\n",
            "Indexing Audit Summary: {'session_id': 'rag-indexing', 'total_events': 10, 'event_counts': {'flow_start': 1, 'node_start': 3, 'node_success': 3, 'flow_transition': 2, 'flow_end': 1}, 'duration_seconds': 33.175775}\n",
            "\n",
            "2. Running Demo Queries...\n",
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xf046ebb2a94883e19cd81d1a8c175843\",\n",
            "        \"span_id\": \"0x496a93cd50b915b2\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x0de4e0c28a888f10\",\n",
            "    \"start_time\": \"2025-09-26T11:51:38.877378Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:39.265387Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"How is data stored in milvus?\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 9,\n",
            "        \"gen_ai.usage.prompt_tokens\": 9,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated embedding for query: How is data stored in milvus?\n",
            "{\n",
            "    \"name\": \"node.QueryEmbedder\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xf046ebb2a94883e19cd81d1a8c175843\",\n",
            "        \"span_id\": \"0x0de4e0c28a888f10\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x5c2905d06059e08b\",\n",
            "    \"start_time\": \"2025-09-26T11:51:38.825921Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:39.266431Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"QueryEmbedder\",\n",
            "        \"node_type\": \"QueryEmbedder\",\n",
            "        \"latency_ms\": 440.4938220977783,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 1536\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Retrieved 3 relevant documents\n",
            "Top match distance: 0.783\n",
            "{\n",
            "    \"name\": \"node.VectorSearcher\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xf046ebb2a94883e19cd81d1a8c175843\",\n",
            "        \"span_id\": \"0xdb11ac846b0ddcec\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x5c2905d06059e08b\",\n",
            "    \"start_time\": \"2025-09-26T11:51:39.267266Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:39.359955Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"VectorSearcher\",\n",
            "        \"node_type\": \"VectorSearcher\",\n",
            "        \"latency_ms\": 92.69547462463379,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 3\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"openai.chat\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xf046ebb2a94883e19cd81d1a8c175843\",\n",
            "        \"span_id\": \"0xa101f45d2c5a872a\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xfc6659ab33e68154\",\n",
            "    \"start_time\": \"2025-09-26T11:51:39.413682Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:40.659637Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"chat\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.prompt.0.role\": \"system\",\n",
            "        \"gen_ai.prompt.0.content\": \"\\n        Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\\n        \",\n",
            "        \"gen_ai.prompt.1.role\": \"user\",\n",
            "        \"gen_ai.prompt.1.content\": \"\\n        Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\\n        <context>\\n         Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\\nHow does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n###\\nHow much does Milvus cost?\\n\\nMilvus is a 100% free open-source project.\\n\\nPlease adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.\\n\\nZilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.\\n\\n###\\n        </context>\\n        <question>\\n        How is data stored in milvus?\\n        </question>\\n        \",\n",
            "        \"gen_ai.request.reasoning_effort\": [],\n",
            "        \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\",\n",
            "        \"gen_ai.response.id\": \"chatcmpl-CK1H9iZDH2o8Ed2fXwtx78AnHNQrO\",\n",
            "        \"llm.usage.total_tokens\": 657,\n",
            "        \"gen_ai.usage.completion_tokens\": 100,\n",
            "        \"gen_ai.usage.prompt_tokens\": 557,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0,\n",
            "        \"gen_ai.usage.reasoning_tokens\": 0,\n",
            "        \"gen_ai.completion.0.finish_reason\": \"stop\",\n",
            "        \"gen_ai.completion.0.role\": \"assistant\",\n",
            "        \"gen_ai.completion.0.content\": \"Milvus stores data in two main ways:\\n1. Inserted data, which includes vector data, scalar data, and collection-specific schema, are stored in persistent storage as an incremental log in different object storage backends like MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, and Tencent Cloud Object Storage (COS).\\n2. Metadata that is generated within Milvus is stored in etcd, and each Milvus module has its own metadata.\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated RAG response:\n",
            "--------------------------------------------------\n",
            "Milvus stores data in two main ways:\n",
            "1. Inserted data, which includes vector data, scalar data, and collection-specific schema, are stored in persistent storage as an incremental log in different object storage backends like MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, and Tencent Cloud Object Storage (COS).\n",
            "2. Metadata that is generated within Milvus is stored in etcd, and each Milvus module has its own metadata.\n",
            "--------------------------------------------------\n",
            "{\n",
            "    \"name\": \"node.ResponseGenerator\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xf046ebb2a94883e19cd81d1a8c175843\",\n",
            "        \"span_id\": \"0xfc6659ab33e68154\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x5c2905d06059e08b\",\n",
            "    \"start_time\": \"2025-09-26T11:51:39.360914Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:40.660689Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"ResponseGenerator\",\n",
            "        \"node_type\": \"ResponseGenerator\",\n",
            "        \"latency_ms\": 1299.8018264770508,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 448\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"flow.RAGQuery\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xf046ebb2a94883e19cd81d1a8c175843\",\n",
            "        \"span_id\": \"0x5c2905d06059e08b\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-09-26T11:51:38.825821Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:40.661282Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"flow_name\": \"RAGQuery\",\n",
            "        \"flow_type\": \"AuditedFlow\",\n",
            "        \"total_latency_ms\": 1835.5076313018799\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "\n",
            "Query Audit Summary: {'session_id': 'rag-query', 'total_events': 10, 'event_counts': {'flow_start': 1, 'node_start': 3, 'node_success': 3, 'flow_transition': 2, 'flow_end': 1}, 'duration_seconds': 1.836282}\n",
            "\n",
            "3. Try another query...\n",
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x0a176d575a6e4283c266474ae45afb9c\",\n",
            "        \"span_id\": \"0x2e3f527f477d6464\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x41a12bcf5682b246\",\n",
            "    \"start_time\": \"2025-09-26T11:51:40.716928Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:41.128614Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"What are the different types of indexes in Milvus?\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 12,\n",
            "        \"gen_ai.usage.prompt_tokens\": 12,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated embedding for query: What are the different types of indexes in Milvus?\n",
            "{\n",
            "    \"name\": \"node.QueryEmbedder\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x0a176d575a6e4283c266474ae45afb9c\",\n",
            "        \"span_id\": \"0x41a12bcf5682b246\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x5ccd3d73983a4b9b\",\n",
            "    \"start_time\": \"2025-09-26T11:51:40.663150Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:41.129580Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"QueryEmbedder\",\n",
            "        \"node_type\": \"QueryEmbedder\",\n",
            "        \"latency_ms\": 466.4144515991211,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 1536\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Retrieved 3 relevant documents\n",
            "Top match distance: 0.657\n",
            "{\n",
            "    \"name\": \"node.VectorSearcher\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x0a176d575a6e4283c266474ae45afb9c\",\n",
            "        \"span_id\": \"0x672330bb7a341ccc\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x5ccd3d73983a4b9b\",\n",
            "    \"start_time\": \"2025-09-26T11:51:41.130348Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:41.132864Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"VectorSearcher\",\n",
            "        \"node_type\": \"VectorSearcher\",\n",
            "        \"latency_ms\": 2.544879913330078,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 3\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"openai.chat\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x0a176d575a6e4283c266474ae45afb9c\",\n",
            "        \"span_id\": \"0xaf5a3d65e9e8a919\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xd9b63ac88ddf6bbb\",\n",
            "    \"start_time\": \"2025-09-26T11:51:41.185859Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:41.932372Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"chat\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.prompt.0.role\": \"system\",\n",
            "        \"gen_ai.prompt.0.content\": \"\\n        Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\\n        \",\n",
            "        \"gen_ai.prompt.1.role\": \"user\",\n",
            "        \"gen_ai.prompt.1.content\": \"\\n        Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\\n        <context>\\n         Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\\nIs Milvus available for concurrent search?\\n\\nYes. For queries on the same collection, Milvus concurrently searches the incremental and historical data. However, queries on different collections are conducted in series. Whereas the historical data can be an extremely huge dataset, searches on the historical data are relatively more time-consuming and essentially performed in series.\\n\\n###\\nHow much does Milvus cost?\\n\\nMilvus is a 100% free open-source project.\\n\\nPlease adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.\\n\\nZilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.\\n\\n###\\n        </context>\\n        <question>\\n        What are the different types of indexes in Milvus?\\n        </question>\\n        \",\n",
            "        \"gen_ai.request.reasoning_effort\": [],\n",
            "        \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\",\n",
            "        \"gen_ai.response.id\": \"chatcmpl-CK1HBtnyXA0upRKji9AbdaAFIrXG7\",\n",
            "        \"llm.usage.total_tokens\": 510,\n",
            "        \"gen_ai.usage.completion_tokens\": 27,\n",
            "        \"gen_ai.usage.prompt_tokens\": 483,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0,\n",
            "        \"gen_ai.usage.reasoning_tokens\": 0,\n",
            "        \"gen_ai.completion.0.finish_reason\": \"stop\",\n",
            "        \"gen_ai.completion.0.role\": \"assistant\",\n",
            "        \"gen_ai.completion.0.content\": \"The provided passage does not contain information regarding the types of indexes in Milvus. Would you like information on another topic or question?\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated RAG response:\n",
            "--------------------------------------------------\n",
            "The provided passage does not contain information regarding the types of indexes in Milvus. Would you like information on another topic or question?\n",
            "--------------------------------------------------\n",
            "{\n",
            "    \"name\": \"node.ResponseGenerator\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x0a176d575a6e4283c266474ae45afb9c\",\n",
            "        \"span_id\": \"0xd9b63ac88ddf6bbb\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x5ccd3d73983a4b9b\",\n",
            "    \"start_time\": \"2025-09-26T11:51:41.133731Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:41.935065Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"ResponseGenerator\",\n",
            "        \"node_type\": \"ResponseGenerator\",\n",
            "        \"latency_ms\": 800.9376525878906,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 148\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"flow.RAGQuery\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x0a176d575a6e4283c266474ae45afb9c\",\n",
            "        \"span_id\": \"0x5ccd3d73983a4b9b\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-09-26T11:51:40.663038Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:41.935738Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"flow_name\": \"RAGQuery\",\n",
            "        \"flow_type\": \"AuditedFlow\",\n",
            "        \"total_latency_ms\": 1272.7484703063965\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "\n",
            "Query Audit Summary: {'session_id': 'rag-query', 'total_events': 10, 'event_counts': {'flow_start': 1, 'node_start': 3, 'node_success': 3, 'flow_transition': 2, 'flow_end': 1}, 'duration_seconds': 1.273449}\n",
            "\n",
            "4. Starting Interactive Mode...\n",
            "\n",
            "============================================================\n",
            "INTERACTIVE RAG CHAT\n",
            "============================================================\n",
            "Ask questions about Milvus! Type 'exit' to quit.\n",
            "------------------------------------------------------------\n",
            "\n",
            "Your question: can you tell me about milvus\n",
            "\n",
            "Processing: can you tell me about milvus\n",
            "----------------------------------------\n",
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x86a208395f7939fd524149718b7f13ec\",\n",
            "        \"span_id\": \"0x8ac440c2973c2b50\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x831f3c4e44b0a1f6\",\n",
            "    \"start_time\": \"2025-09-26T11:51:57.159773Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:57.602303Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"can you tell me about milvus\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 8,\n",
            "        \"gen_ai.usage.prompt_tokens\": 8,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated embedding for query: can you tell me about milvus\n",
            "{\n",
            "    \"name\": \"node.QueryEmbedder\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x86a208395f7939fd524149718b7f13ec\",\n",
            "        \"span_id\": \"0x831f3c4e44b0a1f6\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x68c3e93323ce103e\",\n",
            "    \"start_time\": \"2025-09-26T11:51:57.108552Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:57.603250Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"QueryEmbedder\",\n",
            "        \"node_type\": \"QueryEmbedder\",\n",
            "        \"latency_ms\": 494.6749210357666,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 1536\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Retrieved 3 relevant documents\n",
            "Top match distance: 0.710\n",
            "{\n",
            "    \"name\": \"node.VectorSearcher\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x86a208395f7939fd524149718b7f13ec\",\n",
            "        \"span_id\": \"0x51edf527e6b14cc0\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x68c3e93323ce103e\",\n",
            "    \"start_time\": \"2025-09-26T11:51:57.604004Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:57.606759Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"VectorSearcher\",\n",
            "        \"node_type\": \"VectorSearcher\",\n",
            "        \"latency_ms\": 2.800464630126953,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 3\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"openai.chat\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x86a208395f7939fd524149718b7f13ec\",\n",
            "        \"span_id\": \"0xb1653d2f63409797\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x44708f1746e1efd1\",\n",
            "    \"start_time\": \"2025-09-26T11:51:57.661218Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:59.404777Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"chat\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.prompt.0.role\": \"system\",\n",
            "        \"gen_ai.prompt.0.content\": \"\\n        Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\\n        \",\n",
            "        \"gen_ai.prompt.1.role\": \"user\",\n",
            "        \"gen_ai.prompt.1.content\": \"\\n        Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\\n        <context>\\n        How much does Milvus cost?\\n\\nMilvus is a 100% free open-source project.\\n\\nPlease adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.\\n\\nZilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.\\n\\n###\\n Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\\nStill have questions?\\n\\nYou can:\\n\\n- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. You're welcome to raise questions, share ideas, and help others.\\n- Join our [Slack community](https://slack.milvus.io/) to find support and engage with our open-source community.\\n\\n\\n        </context>\\n        <question>\\n        can you tell me about milvus\\n        </question>\\n        \",\n",
            "        \"gen_ai.request.reasoning_effort\": [],\n",
            "        \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\",\n",
            "        \"gen_ai.response.id\": \"chatcmpl-CK1HRt9EQZyTEPHEmeTDajnKBpHVM\",\n",
            "        \"llm.usage.total_tokens\": 649,\n",
            "        \"gen_ai.usage.completion_tokens\": 162,\n",
            "        \"gen_ai.usage.prompt_tokens\": 487,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0,\n",
            "        \"gen_ai.usage.reasoning_tokens\": 0,\n",
            "        \"gen_ai.completion.0.finish_reason\": \"stop\",\n",
            "        \"gen_ai.completion.0.role\": \"assistant\",\n",
            "        \"gen_ai.completion.0.content\": \"Milvus is a 100% free open-source project offered by Zilliz. It is available under the Apache License 2.0 for production or distribution purposes. Zilliz, the company behind Milvus, also provides a fully managed cloud version called Zilliz Cloud, where users can pay only for what they use. Milvus stores inserted data, including vector data, scalar data, and collection-specific schema, in multiple object storage backends like MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, and Tencent Cloud Object Storage. Metadata within Milvus is generated and stored in etcd. If you have further questions, you can visit Milvus on GitHub or join their Slack community for support and engagement with the open-source community.\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated RAG response:\n",
            "--------------------------------------------------\n",
            "Milvus is a 100% free open-source project offered by Zilliz. It is available under the Apache License 2.0 for production or distribution purposes. Zilliz, the company behind Milvus, also provides a fully managed cloud version called Zilliz Cloud, where users can pay only for what they use. Milvus stores inserted data, including vector data, scalar data, and collection-specific schema, in multiple object storage backends like MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, and Tencent Cloud Object Storage. Metadata within Milvus is generated and stored in etcd. If you have further questions, you can visit Milvus on GitHub or join their Slack community for support and engagement with the open-source community.\n",
            "--------------------------------------------------\n",
            "{\n",
            "    \"name\": \"node.ResponseGenerator\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x86a208395f7939fd524149718b7f13ec\",\n",
            "        \"span_id\": \"0x44708f1746e1efd1\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x68c3e93323ce103e\",\n",
            "    \"start_time\": \"2025-09-26T11:51:57.607507Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:59.405808Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"ResponseGenerator\",\n",
            "        \"node_type\": \"ResponseGenerator\",\n",
            "        \"latency_ms\": 1798.3322143554688,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 745\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"flow.RAGQuery\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x86a208395f7939fd524149718b7f13ec\",\n",
            "        \"span_id\": \"0x68c3e93323ce103e\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-09-26T11:51:57.108452Z\",\n",
            "    \"end_time\": \"2025-09-26T11:51:59.406443Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"flow_name\": \"RAGQuery\",\n",
            "        \"flow_type\": \"AuditedFlow\",\n",
            "        \"total_latency_ms\": 2298.031806945801\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "\n",
            "Query Audit Summary: {'session_id': 'rag-query', 'total_events': 10, 'event_counts': {'flow_start': 1, 'node_start': 3, 'node_success': 3, 'flow_transition': 2, 'flow_end': 1}, 'duration_seconds': 2.306545}\n",
            "\n",
            "Your question: what exactly can i do with mlvus\n",
            "\n",
            "Processing: what exactly can i do with mlvus\n",
            "----------------------------------------\n",
            "{\n",
            "    \"name\": \"openai.embeddings\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xcda863cf25ce5433952357491dbe6606\",\n",
            "        \"span_id\": \"0x46c18c45613e152c\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x1bddb1fa743d172d\",\n",
            "    \"start_time\": \"2025-09-26T11:52:25.927475Z\",\n",
            "    \"end_time\": \"2025-09-26T11:52:26.374603Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"embedding\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.prompt.0.content\": \"what exactly can i do with mlvus\",\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.response.model\": \"text-embedding-3-small\",\n",
            "        \"llm.usage.total_tokens\": 9,\n",
            "        \"gen_ai.usage.prompt_tokens\": 9,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated embedding for query: what exactly can i do with mlvus\n",
            "{\n",
            "    \"name\": \"node.QueryEmbedder\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xcda863cf25ce5433952357491dbe6606\",\n",
            "        \"span_id\": \"0x1bddb1fa743d172d\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0xe481e9f8d58c4982\",\n",
            "    \"start_time\": \"2025-09-26T11:52:25.875646Z\",\n",
            "    \"end_time\": \"2025-09-26T11:52:26.375566Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"QueryEmbedder\",\n",
            "        \"node_type\": \"QueryEmbedder\",\n",
            "        \"latency_ms\": 499.94707107543945,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 1536\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Retrieved 3 relevant documents\n",
            "Top match distance: 0.438\n",
            "{\n",
            "    \"name\": \"node.VectorSearcher\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xcda863cf25ce5433952357491dbe6606\",\n",
            "        \"span_id\": \"0xab0bad0f0036b5fa\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0xe481e9f8d58c4982\",\n",
            "    \"start_time\": \"2025-09-26T11:52:26.376331Z\",\n",
            "    \"end_time\": \"2025-09-26T11:52:26.380155Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"VectorSearcher\",\n",
            "        \"node_type\": \"VectorSearcher\",\n",
            "        \"latency_ms\": 3.8666725158691406,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 3\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"openai.chat\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xcda863cf25ce5433952357491dbe6606\",\n",
            "        \"span_id\": \"0x6f9baf5788693485\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x91f2406817855120\",\n",
            "    \"start_time\": \"2025-09-26T11:52:26.434053Z\",\n",
            "    \"end_time\": \"2025-09-26T11:52:27.527515Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"llm.request.type\": \"chat\",\n",
            "        \"gen_ai.system\": \"openai\",\n",
            "        \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
            "        \"llm.headers\": \"None\",\n",
            "        \"llm.is_streaming\": false,\n",
            "        \"gen_ai.openai.api_base\": \"https://api.openai.com/v1/\",\n",
            "        \"gen_ai.prompt.0.role\": \"system\",\n",
            "        \"gen_ai.prompt.0.content\": \"\\n        Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\\n        \",\n",
            "        \"gen_ai.prompt.1.role\": \"user\",\n",
            "        \"gen_ai.prompt.1.content\": \"\\n        Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\\n        <context>\\n        How much does Milvus cost?\\n\\nMilvus is a 100% free open-source project.\\n\\nPlease adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.\\n\\nZilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.\\n\\n###\\n Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\\nHow do I know if my CPU supports Milvus?\\n\\n{{fragments/cpu_support.md}}\\n\\n###\\n        </context>\\n        <question>\\n        what exactly can i do with mlvus\\n        </question>\\n        \",\n",
            "        \"gen_ai.request.reasoning_effort\": [],\n",
            "        \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\",\n",
            "        \"gen_ai.response.id\": \"chatcmpl-CK1HutPlGQBsQXThZbUhbfHwMPDQq\",\n",
            "        \"llm.usage.total_tokens\": 530,\n",
            "        \"gen_ai.usage.completion_tokens\": 97,\n",
            "        \"gen_ai.usage.prompt_tokens\": 433,\n",
            "        \"gen_ai.usage.cache_read_input_tokens\": 0,\n",
            "        \"gen_ai.usage.reasoning_tokens\": 0,\n",
            "        \"gen_ai.completion.0.finish_reason\": \"stop\",\n",
            "        \"gen_ai.completion.0.role\": \"assistant\",\n",
            "        \"gen_ai.completion.0.content\": \"Milvus is a platform that deals with two types of data: inserted data and metadata. Inserted data, which includes vector data, scalar data, and collection-specific schema, is stored in persistent storage as incremental logs. Milvus supports multiple object storage backends for storing data, such as MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, and Tencent Cloud Object Storage. Metadata generated within Milvus is stored in etcd.\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Generated RAG response:\n",
            "--------------------------------------------------\n",
            "Milvus is a platform that deals with two types of data: inserted data and metadata. Inserted data, which includes vector data, scalar data, and collection-specific schema, is stored in persistent storage as incremental logs. Milvus supports multiple object storage backends for storing data, such as MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, and Tencent Cloud Object Storage. Metadata generated within Milvus is stored in etcd.\n",
            "--------------------------------------------------\n",
            "{\n",
            "    \"name\": \"node.ResponseGenerator\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xcda863cf25ce5433952357491dbe6606\",\n",
            "        \"span_id\": \"0x91f2406817855120\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0xe481e9f8d58c4982\",\n",
            "    \"start_time\": \"2025-09-26T11:52:26.380927Z\",\n",
            "    \"end_time\": \"2025-09-26T11:52:27.528647Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"node_name\": \"ResponseGenerator\",\n",
            "        \"node_type\": \"ResponseGenerator\",\n",
            "        \"latency_ms\": 1147.7274894714355,\n",
            "        \"result_type\": \"str\",\n",
            "        \"batch_size\": 461\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"flow.RAGQuery\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xcda863cf25ce5433952357491dbe6606\",\n",
            "        \"span_id\": \"0xe481e9f8d58c4982\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-09-26T11:52:25.875501Z\",\n",
            "    \"end_time\": \"2025-09-26T11:52:27.529408Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"UNSET\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"flow_name\": \"RAGQuery\",\n",
            "        \"flow_type\": \"AuditedFlow\",\n",
            "        \"total_latency_ms\": 1653.9411544799805\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.37.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "\n",
            "Query Audit Summary: {'session_id': 'rag-query', 'total_events': 10, 'event_counts': {'flow_start': 1, 'node_start': 3, 'node_success': 3, 'flow_transition': 2, 'flow_end': 1}, 'duration_seconds': 1.654712}\n",
            "\n",
            "Your question: exit\n",
            "Thanks for using RAG with Agora!\n",
            "\n",
            "RAG Demo Complete!\n",
            "Check the audit JSON files for detailed execution logs.\n"
          ]
        }
      ]
    }
  ]
}